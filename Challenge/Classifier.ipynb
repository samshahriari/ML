{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          y         x1       x2         x3       x4         x5         x6  \\\n",
      "0     Allan   99.12807 -0.23827  -99.18350 -1.25286  199.18948 -138.43341   \n",
      "1    Barbie   98.89017 -0.75339 -101.87005 -1.28567  198.95956 -143.84561   \n",
      "2     Allan   99.82120  0.84490  -99.44376 -1.28067  199.89075 -146.86712   \n",
      "3       Ken   99.30343 -0.63459  -99.05639 -1.28568  199.37161 -148.10247   \n",
      "4    Barbie  101.20987  0.57183  -97.35634 -1.24798  201.26858 -141.67514   \n",
      "..      ...        ...      ...        ...      ...        ...        ...   \n",
      "995     Ken   99.98105  0.57266 -104.97494 -1.29567  200.05220 -150.23099   \n",
      "996  Barbie  101.17428  1.12203  -96.29229 -1.26965  201.23923 -146.06461   \n",
      "997     Ken  100.95875 -0.38762 -105.84354 -1.26880  201.02343 -145.51066   \n",
      "998   Allan   98.60921 -0.44551 -100.04885 -1.29410  198.68223 -146.35393   \n",
      "999  Barbie  100.30344  0.21961  -98.41096 -1.27372  200.36953 -146.55866   \n",
      "\n",
      "            x7       x8       x9       x10      x11   x12        x13  \n",
      "0        Beach -1.35039  0.84187   9.90459  1.71861  True  446.04860  \n",
      "1       Horses  0.11728 -0.20714   9.75938 -1.19782  True  443.51583  \n",
      "2        Beach -0.05036 -0.24721  13.83337  3.54015  True  449.38413  \n",
      "3        Beach -0.08433  0.83271   9.70324  3.03869  True  446.98894  \n",
      "4     Mojodojo  1.46646  0.32269  10.75488 -3.12135  True  457.37120  \n",
      "..         ...      ...      ...       ...      ...   ...        ...  \n",
      "995      Beach -0.46925 -0.48204   9.99696 -1.52633  True  447.41779  \n",
      "996   Mojodojo -0.62715  0.54826  10.83764 -2.98875  True  457.72528  \n",
      "997  Casahouse -2.69301 -0.64138  13.02011  0.51648  True  451.87196  \n",
      "998     Horses  0.69854 -0.65816  11.02607  3.28680  True  443.02162  \n",
      "999  Casahouse -1.96503  0.64113   9.16362 -0.51032  True  452.31170  \n",
      "\n",
      "[1000 rows x 14 columns]\n",
      "              x1       x2         x3       x4         x5         x6  \\\n",
      "1000    99.24698 -0.46355  -96.68109 -1.25631  199.30889 -140.94793   \n",
      "1001   100.69112 -0.76481  -97.75936 -1.28079  200.76051 -148.57147   \n",
      "1002   100.45979 -0.18150  -96.72271 -1.27106  200.52695 -145.68474   \n",
      "1003    99.61802 -0.72028  -95.77843 -1.25958  199.68197 -140.95782   \n",
      "1004    98.75375  0.11960 -100.78892 -1.29145  198.82468 -146.90710   \n",
      "...          ...      ...        ...      ...        ...        ...   \n",
      "10995   99.27497  0.81171  -97.15838 -1.23166  199.33180 -134.58899   \n",
      "10996   99.44584 -2.10637  -99.07363 -1.24637  199.50647 -138.39773   \n",
      "10997  101.18489  0.40643  -98.93466 -1.25953  201.24679 -141.78880   \n",
      "10998  100.66202 -0.14533 -100.39213 -1.29244  200.73270 -148.34222   \n",
      "10999   99.33307  1.35519  -99.41588 -1.30303  199.40768 -152.97629   \n",
      "\n",
      "              x7       x8       x9       x10      x11   x12        x13  \n",
      "1000       Beach  1.07024 -0.47506  11.23413  2.57510  True  447.89434  \n",
      "1001   Casahouse  0.06501 -0.22026   9.38919  1.15893  True  454.57590  \n",
      "1002   Casahouse  0.75997  0.35594  11.35137  3.73002  True  453.93761  \n",
      "1003       Beach  0.24756  0.10611  12.20488 -1.58528  True  450.20090  \n",
      "1004      Horses  1.92500  0.51205  10.08860 -4.60008  True  443.37427  \n",
      "...          ...      ...      ...       ...      ...   ...        ...  \n",
      "10995      Beach  0.28281  1.33993  10.48453  5.16527  True  447.79565  \n",
      "10996      Beach -0.24611 -0.16089  11.55327 -1.79904  True  447.69238  \n",
      "10997   Mojodojo -0.90676 -1.86165  12.64823 -2.10815  True  456.45712  \n",
      "10998  Casahouse -0.15034 -2.93226  12.61312 -2.60304  True  453.11406  \n",
      "10999      Beach  0.00420  0.43269  11.04964  1.66140  True  446.95742  \n",
      "\n",
      "[10000 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "training_data = pd.read_csv(\"./TrainOnMe_orig.csv\", index_col=0)\n",
    "evaluation_data = pd.read_csv(\"./EvaluateOnMe.csv\", index_col=0)\n",
    "print(training_data)\n",
    "print(evaluation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   y       1000 non-null   object \n",
      " 1   x1      1000 non-null   float64\n",
      " 2   x2      1000 non-null   float64\n",
      " 3   x3      1000 non-null   float64\n",
      " 4   x4      1000 non-null   float64\n",
      " 5   x5      1000 non-null   float64\n",
      " 6   x6      1000 non-null   float64\n",
      " 7   x7      1000 non-null   object \n",
      " 8   x8      1000 non-null   float64\n",
      " 9   x9      1000 non-null   float64\n",
      " 10  x10     1000 non-null   float64\n",
      " 11  x11     1000 non-null   float64\n",
      " 12  x12     1000 non-null   bool   \n",
      " 13  x13     1000 non-null   float64\n",
      "dtypes: bool(1), float64(11), object(2)\n",
      "memory usage: 110.4+ KB\n"
     ]
    }
   ],
   "source": [
    "training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Barbie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Casahouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.014591</td>\n",
       "      <td>-0.000887</td>\n",
       "      <td>-100.076426</td>\n",
       "      <td>-1.267901</td>\n",
       "      <td>200.079503</td>\n",
       "      <td>-143.727963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059994</td>\n",
       "      <td>-0.068097</td>\n",
       "      <td>11.102700</td>\n",
       "      <td>-0.454393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450.034744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992759</td>\n",
       "      <td>0.696235</td>\n",
       "      <td>3.197438</td>\n",
       "      <td>0.019526</td>\n",
       "      <td>0.992486</td>\n",
       "      <td>4.337238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.203451</td>\n",
       "      <td>1.216253</td>\n",
       "      <td>1.343901</td>\n",
       "      <td>2.164375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.658678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>96.955490</td>\n",
       "      <td>-2.174030</td>\n",
       "      <td>-109.430380</td>\n",
       "      <td>-1.315050</td>\n",
       "      <td>197.025890</td>\n",
       "      <td>-155.176740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.146800</td>\n",
       "      <td>-4.735020</td>\n",
       "      <td>6.697050</td>\n",
       "      <td>-6.255740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>434.849820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>99.378385</td>\n",
       "      <td>-0.456977</td>\n",
       "      <td>-102.244197</td>\n",
       "      <td>-1.282540</td>\n",
       "      <td>199.444772</td>\n",
       "      <td>-146.739633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.641962</td>\n",
       "      <td>-0.775660</td>\n",
       "      <td>10.272842</td>\n",
       "      <td>-2.020060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>447.011275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.026960</td>\n",
       "      <td>-0.023120</td>\n",
       "      <td>-100.059655</td>\n",
       "      <td>-1.269980</td>\n",
       "      <td>200.091395</td>\n",
       "      <td>-143.971965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>-0.049365</td>\n",
       "      <td>11.203200</td>\n",
       "      <td>-0.721095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>449.929060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.693105</td>\n",
       "      <td>0.471495</td>\n",
       "      <td>-97.934903</td>\n",
       "      <td>-1.253488</td>\n",
       "      <td>200.757617</td>\n",
       "      <td>-140.711602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762282</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>11.939948</td>\n",
       "      <td>1.200600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>453.308058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>103.181080</td>\n",
       "      <td>2.113890</td>\n",
       "      <td>-90.396560</td>\n",
       "      <td>-1.220360</td>\n",
       "      <td>203.246900</td>\n",
       "      <td>-129.967130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.525250</td>\n",
       "      <td>3.710860</td>\n",
       "      <td>15.941560</td>\n",
       "      <td>5.076820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>464.076640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y           x1           x2           x3           x4  \\\n",
       "count     1000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "unique       3          NaN          NaN          NaN          NaN   \n",
       "top     Barbie          NaN          NaN          NaN          NaN   \n",
       "freq       402          NaN          NaN          NaN          NaN   \n",
       "mean       NaN   100.014591    -0.000887  -100.076426    -1.267901   \n",
       "std        NaN     0.992759     0.696235     3.197438     0.019526   \n",
       "min        NaN    96.955490    -2.174030  -109.430380    -1.315050   \n",
       "25%        NaN    99.378385    -0.456977  -102.244197    -1.282540   \n",
       "50%        NaN   100.026960    -0.023120  -100.059655    -1.269980   \n",
       "75%        NaN   100.693105     0.471495   -97.934903    -1.253488   \n",
       "max        NaN   103.181080     2.113890   -90.396560    -1.220360   \n",
       "\n",
       "                 x5           x6         x7           x8           x9  \\\n",
       "count   1000.000000  1000.000000       1000  1000.000000  1000.000000   \n",
       "unique          NaN          NaN          5          NaN          NaN   \n",
       "top             NaN          NaN  Casahouse          NaN          NaN   \n",
       "freq            NaN          NaN        341          NaN          NaN   \n",
       "mean     200.079503  -143.727963        NaN     0.059994    -0.068097   \n",
       "std        0.992486     4.337238        NaN     1.203451     1.216253   \n",
       "min      197.025890  -155.176740        NaN    -4.146800    -4.735020   \n",
       "25%      199.444772  -146.739633        NaN    -0.641962    -0.775660   \n",
       "50%      200.091395  -143.971965        NaN     0.082900    -0.049365   \n",
       "75%      200.757617  -140.711602        NaN     0.762282     0.681373   \n",
       "max      203.246900  -129.967130        NaN     4.525250     3.710860   \n",
       "\n",
       "                x10          x11   x12          x13  \n",
       "count   1000.000000  1000.000000  1000  1000.000000  \n",
       "unique          NaN          NaN     1          NaN  \n",
       "top             NaN          NaN  True          NaN  \n",
       "freq            NaN          NaN  1000          NaN  \n",
       "mean      11.102700    -0.454393   NaN   450.034744  \n",
       "std        1.343901     2.164375   NaN     4.658678  \n",
       "min        6.697050    -6.255740   NaN   434.849820  \n",
       "25%       10.272842    -2.020060   NaN   447.011275  \n",
       "50%       11.203200    -0.721095   NaN   449.929060  \n",
       "75%       11.939948     1.200600   NaN   453.308058  \n",
       "max       15.941560     5.076820   NaN   464.076640  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: check if some rows should be removed if they are outside a 99 % confidence interval. Compare this to rows not removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "Barbie    402\n",
       "Allan     315\n",
       "Ken       283\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x7\n",
       "Casahouse    341\n",
       "Beach        335\n",
       "Horses       158\n",
       "Mojodojo     147\n",
       "Sublime       19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['x7'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels for feature x7 is not \"on a scale\" so we should use OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x7_Beach</th>\n",
       "      <th>x7_Casahouse</th>\n",
       "      <th>x7_Horses</th>\n",
       "      <th>x7_Mojodojo</th>\n",
       "      <th>x7_Sublime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Barbie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>665</td>\n",
       "      <td>659</td>\n",
       "      <td>842</td>\n",
       "      <td>853</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.014591</td>\n",
       "      <td>-0.000887</td>\n",
       "      <td>-100.076426</td>\n",
       "      <td>-1.267901</td>\n",
       "      <td>200.079503</td>\n",
       "      <td>-143.727963</td>\n",
       "      <td>0.059994</td>\n",
       "      <td>-0.068097</td>\n",
       "      <td>11.102700</td>\n",
       "      <td>-0.454393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450.034744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992759</td>\n",
       "      <td>0.696235</td>\n",
       "      <td>3.197438</td>\n",
       "      <td>0.019526</td>\n",
       "      <td>0.992486</td>\n",
       "      <td>4.337238</td>\n",
       "      <td>1.203451</td>\n",
       "      <td>1.216253</td>\n",
       "      <td>1.343901</td>\n",
       "      <td>2.164375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.658678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>96.955490</td>\n",
       "      <td>-2.174030</td>\n",
       "      <td>-109.430380</td>\n",
       "      <td>-1.315050</td>\n",
       "      <td>197.025890</td>\n",
       "      <td>-155.176740</td>\n",
       "      <td>-4.146800</td>\n",
       "      <td>-4.735020</td>\n",
       "      <td>6.697050</td>\n",
       "      <td>-6.255740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>434.849820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>99.378385</td>\n",
       "      <td>-0.456977</td>\n",
       "      <td>-102.244197</td>\n",
       "      <td>-1.282540</td>\n",
       "      <td>199.444772</td>\n",
       "      <td>-146.739633</td>\n",
       "      <td>-0.641962</td>\n",
       "      <td>-0.775660</td>\n",
       "      <td>10.272842</td>\n",
       "      <td>-2.020060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>447.011275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.026960</td>\n",
       "      <td>-0.023120</td>\n",
       "      <td>-100.059655</td>\n",
       "      <td>-1.269980</td>\n",
       "      <td>200.091395</td>\n",
       "      <td>-143.971965</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>-0.049365</td>\n",
       "      <td>11.203200</td>\n",
       "      <td>-0.721095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>449.929060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.693105</td>\n",
       "      <td>0.471495</td>\n",
       "      <td>-97.934903</td>\n",
       "      <td>-1.253488</td>\n",
       "      <td>200.757617</td>\n",
       "      <td>-140.711602</td>\n",
       "      <td>0.762282</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>11.939948</td>\n",
       "      <td>1.200600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>453.308058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>103.181080</td>\n",
       "      <td>2.113890</td>\n",
       "      <td>-90.396560</td>\n",
       "      <td>-1.220360</td>\n",
       "      <td>203.246900</td>\n",
       "      <td>-129.967130</td>\n",
       "      <td>4.525250</td>\n",
       "      <td>3.710860</td>\n",
       "      <td>15.941560</td>\n",
       "      <td>5.076820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>464.076640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y           x1           x2           x3           x4  \\\n",
       "count     1000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "unique       3          NaN          NaN          NaN          NaN   \n",
       "top     Barbie          NaN          NaN          NaN          NaN   \n",
       "freq       402          NaN          NaN          NaN          NaN   \n",
       "mean       NaN   100.014591    -0.000887  -100.076426    -1.267901   \n",
       "std        NaN     0.992759     0.696235     3.197438     0.019526   \n",
       "min        NaN    96.955490    -2.174030  -109.430380    -1.315050   \n",
       "25%        NaN    99.378385    -0.456977  -102.244197    -1.282540   \n",
       "50%        NaN   100.026960    -0.023120  -100.059655    -1.269980   \n",
       "75%        NaN   100.693105     0.471495   -97.934903    -1.253488   \n",
       "max        NaN   103.181080     2.113890   -90.396560    -1.220360   \n",
       "\n",
       "                 x5           x6           x8           x9          x10  \\\n",
       "count   1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean     200.079503  -143.727963     0.059994    -0.068097    11.102700   \n",
       "std        0.992486     4.337238     1.203451     1.216253     1.343901   \n",
       "min      197.025890  -155.176740    -4.146800    -4.735020     6.697050   \n",
       "25%      199.444772  -146.739633    -0.641962    -0.775660    10.272842   \n",
       "50%      200.091395  -143.971965     0.082900    -0.049365    11.203200   \n",
       "75%      200.757617  -140.711602     0.762282     0.681373    11.939948   \n",
       "max      203.246900  -129.967130     4.525250     3.710860    15.941560   \n",
       "\n",
       "                x11   x12          x13 x7_Beach x7_Casahouse x7_Horses  \\\n",
       "count   1000.000000  1000  1000.000000     1000         1000      1000   \n",
       "unique          NaN     1          NaN        2            2         2   \n",
       "top             NaN  True          NaN    False        False     False   \n",
       "freq            NaN  1000          NaN      665          659       842   \n",
       "mean      -0.454393   NaN   450.034744      NaN          NaN       NaN   \n",
       "std        2.164375   NaN     4.658678      NaN          NaN       NaN   \n",
       "min       -6.255740   NaN   434.849820      NaN          NaN       NaN   \n",
       "25%       -2.020060   NaN   447.011275      NaN          NaN       NaN   \n",
       "50%       -0.721095   NaN   449.929060      NaN          NaN       NaN   \n",
       "75%        1.200600   NaN   453.308058      NaN          NaN       NaN   \n",
       "max        5.076820   NaN   464.076640      NaN          NaN       NaN   \n",
       "\n",
       "       x7_Mojodojo x7_Sublime  \n",
       "count         1000       1000  \n",
       "unique           2          2  \n",
       "top          False      False  \n",
       "freq           853        981  \n",
       "mean           NaN        NaN  \n",
       "std            NaN        NaN  \n",
       "min            NaN        NaN  \n",
       "25%            NaN        NaN  \n",
       "50%            NaN        NaN  \n",
       "75%            NaN        NaN  \n",
       "max            NaN        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# OneHotEncoder()\n",
    "\n",
    "training_data = pd.get_dummies(training_data, columns=['x7'])\n",
    "training_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x7_Beach</th>\n",
       "      <th>x7_Casahouse</th>\n",
       "      <th>x7_Horses</th>\n",
       "      <th>x7_Mojodojo</th>\n",
       "      <th>x7_Sublime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6601</td>\n",
       "      <td>6556</td>\n",
       "      <td>8423</td>\n",
       "      <td>8641</td>\n",
       "      <td>9779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>100.002717</td>\n",
       "      <td>-0.001437</td>\n",
       "      <td>-99.980366</td>\n",
       "      <td>-1.268080</td>\n",
       "      <td>200.067667</td>\n",
       "      <td>-143.713659</td>\n",
       "      <td>-0.008242</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>11.083016</td>\n",
       "      <td>-0.358414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450.023403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.996423</td>\n",
       "      <td>0.710673</td>\n",
       "      <td>3.204113</td>\n",
       "      <td>0.019437</td>\n",
       "      <td>0.996407</td>\n",
       "      <td>4.382318</td>\n",
       "      <td>1.234325</td>\n",
       "      <td>1.227626</td>\n",
       "      <td>1.385592</td>\n",
       "      <td>2.219883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.724378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>95.865820</td>\n",
       "      <td>-2.654930</td>\n",
       "      <td>-112.550120</td>\n",
       "      <td>-1.314910</td>\n",
       "      <td>195.935520</td>\n",
       "      <td>-156.978370</td>\n",
       "      <td>-5.434530</td>\n",
       "      <td>-5.963850</td>\n",
       "      <td>5.171810</td>\n",
       "      <td>-6.582860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>430.286230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>99.329932</td>\n",
       "      <td>-0.489657</td>\n",
       "      <td>-102.130898</td>\n",
       "      <td>-1.282713</td>\n",
       "      <td>199.392997</td>\n",
       "      <td>-146.908408</td>\n",
       "      <td>-0.753343</td>\n",
       "      <td>-0.742583</td>\n",
       "      <td>10.194307</td>\n",
       "      <td>-2.015030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>446.806078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100.010780</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>-100.005950</td>\n",
       "      <td>-1.269940</td>\n",
       "      <td>200.077105</td>\n",
       "      <td>-143.913690</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.011460</td>\n",
       "      <td>11.085695</td>\n",
       "      <td>-0.710480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450.079855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.680152</td>\n",
       "      <td>0.490008</td>\n",
       "      <td>-97.830355</td>\n",
       "      <td>-1.253880</td>\n",
       "      <td>200.745025</td>\n",
       "      <td>-140.542995</td>\n",
       "      <td>0.736010</td>\n",
       "      <td>0.748163</td>\n",
       "      <td>11.986020</td>\n",
       "      <td>1.369968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>453.249597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>103.580320</td>\n",
       "      <td>3.203900</td>\n",
       "      <td>-88.434500</td>\n",
       "      <td>-1.219530</td>\n",
       "      <td>203.654640</td>\n",
       "      <td>-131.017980</td>\n",
       "      <td>4.863030</td>\n",
       "      <td>5.051730</td>\n",
       "      <td>17.092580</td>\n",
       "      <td>7.122580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>466.579740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x1            x2            x3            x4            x5  \\\n",
       "count   10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean      100.002717     -0.001437    -99.980366     -1.268080    200.067667   \n",
       "std         0.996423      0.710673      3.204113      0.019437      0.996407   \n",
       "min        95.865820     -2.654930   -112.550120     -1.314910    195.935520   \n",
       "25%        99.329932     -0.489657   -102.130898     -1.282713    199.392997   \n",
       "50%       100.010780      0.004730   -100.005950     -1.269940    200.077105   \n",
       "75%       100.680152      0.490008    -97.830355     -1.253880    200.745025   \n",
       "max       103.580320      3.203900    -88.434500     -1.219530    203.654640   \n",
       "\n",
       "                  x6            x8            x9           x10           x11  \\\n",
       "count   10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean     -143.713659     -0.008242      0.004514     11.083016     -0.358414   \n",
       "std         4.382318      1.234325      1.227626      1.385592      2.219883   \n",
       "min      -156.978370     -5.434530     -5.963850      5.171810     -6.582860   \n",
       "25%      -146.908408     -0.753343     -0.742583     10.194307     -2.015030   \n",
       "50%      -143.913690      0.001415      0.011460     11.085695     -0.710480   \n",
       "75%      -140.542995      0.736010      0.748163     11.986020      1.369968   \n",
       "max      -131.017980      4.863030      5.051730     17.092580      7.122580   \n",
       "\n",
       "          x12           x13 x7_Beach x7_Casahouse x7_Horses x7_Mojodojo  \\\n",
       "count   10000  10000.000000    10000        10000     10000       10000   \n",
       "unique      1           NaN        2            2         2           2   \n",
       "top      True           NaN    False        False     False       False   \n",
       "freq    10000           NaN     6601         6556      8423        8641   \n",
       "mean      NaN    450.023403      NaN          NaN       NaN         NaN   \n",
       "std       NaN      4.724378      NaN          NaN       NaN         NaN   \n",
       "min       NaN    430.286230      NaN          NaN       NaN         NaN   \n",
       "25%       NaN    446.806078      NaN          NaN       NaN         NaN   \n",
       "50%       NaN    450.079855      NaN          NaN       NaN         NaN   \n",
       "75%       NaN    453.249597      NaN          NaN       NaN         NaN   \n",
       "max       NaN    466.579740      NaN          NaN       NaN         NaN   \n",
       "\n",
       "       x7_Sublime  \n",
       "count       10000  \n",
       "unique          2  \n",
       "top         False  \n",
       "freq         9779  \n",
       "mean          NaN  \n",
       "std           NaN  \n",
       "min           NaN  \n",
       "25%           NaN  \n",
       "50%           NaN  \n",
       "75%           NaN  \n",
       "max           NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_data = pd.get_dummies(evaluation_data, columns=['x7'])\n",
    "evaluation_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x12\n",
       "True    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['x12'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that every value in x12 is True. We can probably just drop that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 0 to 999\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   y             1000 non-null   object \n",
      " 1   x1            1000 non-null   float64\n",
      " 2   x2            1000 non-null   float64\n",
      " 3   x3            1000 non-null   float64\n",
      " 4   x4            1000 non-null   float64\n",
      " 5   x5            1000 non-null   float64\n",
      " 6   x6            1000 non-null   float64\n",
      " 7   x8            1000 non-null   float64\n",
      " 8   x9            1000 non-null   float64\n",
      " 9   x10           1000 non-null   float64\n",
      " 10  x11           1000 non-null   float64\n",
      " 11  x13           1000 non-null   float64\n",
      " 12  x7_Beach      1000 non-null   bool   \n",
      " 13  x7_Casahouse  1000 non-null   bool   \n",
      " 14  x7_Horses     1000 non-null   bool   \n",
      " 15  x7_Mojodojo   1000 non-null   bool   \n",
      " 16  x7_Sublime    1000 non-null   bool   \n",
      "dtypes: bool(5), float64(11), object(1)\n",
      "memory usage: 106.4+ KB\n"
     ]
    }
   ],
   "source": [
    "training_data = training_data.drop(\"x12\",  axis=1)\n",
    "evaluation_data = evaluation_data.drop(\"x12\",  axis=1)\n",
    "training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_data.copy().drop('y', axis=1)\n",
    "y = training_data.copy()['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x13</th>\n",
       "      <th>x7_Beach</th>\n",
       "      <th>x7_Casahouse</th>\n",
       "      <th>x7_Horses</th>\n",
       "      <th>x7_Mojodojo</th>\n",
       "      <th>x7_Sublime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>665</td>\n",
       "      <td>659</td>\n",
       "      <td>842</td>\n",
       "      <td>853</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>100.014591</td>\n",
       "      <td>-0.000887</td>\n",
       "      <td>-100.076426</td>\n",
       "      <td>-1.267901</td>\n",
       "      <td>200.079503</td>\n",
       "      <td>-143.727963</td>\n",
       "      <td>0.059994</td>\n",
       "      <td>-0.068097</td>\n",
       "      <td>11.102700</td>\n",
       "      <td>-0.454393</td>\n",
       "      <td>450.034744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.992759</td>\n",
       "      <td>0.696235</td>\n",
       "      <td>3.197438</td>\n",
       "      <td>0.019526</td>\n",
       "      <td>0.992486</td>\n",
       "      <td>4.337238</td>\n",
       "      <td>1.203451</td>\n",
       "      <td>1.216253</td>\n",
       "      <td>1.343901</td>\n",
       "      <td>2.164375</td>\n",
       "      <td>4.658678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>96.955490</td>\n",
       "      <td>-2.174030</td>\n",
       "      <td>-109.430380</td>\n",
       "      <td>-1.315050</td>\n",
       "      <td>197.025890</td>\n",
       "      <td>-155.176740</td>\n",
       "      <td>-4.146800</td>\n",
       "      <td>-4.735020</td>\n",
       "      <td>6.697050</td>\n",
       "      <td>-6.255740</td>\n",
       "      <td>434.849820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>99.378385</td>\n",
       "      <td>-0.456977</td>\n",
       "      <td>-102.244197</td>\n",
       "      <td>-1.282540</td>\n",
       "      <td>199.444772</td>\n",
       "      <td>-146.739633</td>\n",
       "      <td>-0.641962</td>\n",
       "      <td>-0.775660</td>\n",
       "      <td>10.272842</td>\n",
       "      <td>-2.020060</td>\n",
       "      <td>447.011275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100.026960</td>\n",
       "      <td>-0.023120</td>\n",
       "      <td>-100.059655</td>\n",
       "      <td>-1.269980</td>\n",
       "      <td>200.091395</td>\n",
       "      <td>-143.971965</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>-0.049365</td>\n",
       "      <td>11.203200</td>\n",
       "      <td>-0.721095</td>\n",
       "      <td>449.929060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.693105</td>\n",
       "      <td>0.471495</td>\n",
       "      <td>-97.934903</td>\n",
       "      <td>-1.253488</td>\n",
       "      <td>200.757617</td>\n",
       "      <td>-140.711602</td>\n",
       "      <td>0.762282</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>11.939948</td>\n",
       "      <td>1.200600</td>\n",
       "      <td>453.308058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>103.181080</td>\n",
       "      <td>2.113890</td>\n",
       "      <td>-90.396560</td>\n",
       "      <td>-1.220360</td>\n",
       "      <td>203.246900</td>\n",
       "      <td>-129.967130</td>\n",
       "      <td>4.525250</td>\n",
       "      <td>3.710860</td>\n",
       "      <td>15.941560</td>\n",
       "      <td>5.076820</td>\n",
       "      <td>464.076640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x1           x2           x3           x4           x5  \\\n",
       "count   1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean     100.014591    -0.000887  -100.076426    -1.267901   200.079503   \n",
       "std        0.992759     0.696235     3.197438     0.019526     0.992486   \n",
       "min       96.955490    -2.174030  -109.430380    -1.315050   197.025890   \n",
       "25%       99.378385    -0.456977  -102.244197    -1.282540   199.444772   \n",
       "50%      100.026960    -0.023120  -100.059655    -1.269980   200.091395   \n",
       "75%      100.693105     0.471495   -97.934903    -1.253488   200.757617   \n",
       "max      103.181080     2.113890   -90.396560    -1.220360   203.246900   \n",
       "\n",
       "                 x6           x8           x9          x10          x11  \\\n",
       "count   1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean    -143.727963     0.059994    -0.068097    11.102700    -0.454393   \n",
       "std        4.337238     1.203451     1.216253     1.343901     2.164375   \n",
       "min     -155.176740    -4.146800    -4.735020     6.697050    -6.255740   \n",
       "25%     -146.739633    -0.641962    -0.775660    10.272842    -2.020060   \n",
       "50%     -143.971965     0.082900    -0.049365    11.203200    -0.721095   \n",
       "75%     -140.711602     0.762282     0.681373    11.939948     1.200600   \n",
       "max     -129.967130     4.525250     3.710860    15.941560     5.076820   \n",
       "\n",
       "                x13 x7_Beach x7_Casahouse x7_Horses x7_Mojodojo x7_Sublime  \n",
       "count   1000.000000     1000         1000      1000        1000       1000  \n",
       "unique          NaN        2            2         2           2          2  \n",
       "top             NaN    False        False     False       False      False  \n",
       "freq            NaN      665          659       842         853        981  \n",
       "mean     450.034744      NaN          NaN       NaN         NaN        NaN  \n",
       "std        4.658678      NaN          NaN       NaN         NaN        NaN  \n",
       "min      434.849820      NaN          NaN       NaN         NaN        NaN  \n",
       "25%      447.011275      NaN          NaN       NaN         NaN        NaN  \n",
       "50%      449.929060      NaN          NaN       NaN         NaN        NaN  \n",
       "75%      453.308058      NaN          NaN       NaN         NaN        NaN  \n",
       "max      464.076640      NaN          NaN       NaN         NaN        NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       1000\n",
       "unique         3\n",
       "top       Barbie\n",
       "freq         402\n",
       "Name: y, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed SVM rbf 0.40199999999999997\n",
      "completed SVM poly 0.40199999999999997\n",
      "completed SVM line 0.704\n",
      "completed SVM sig 0.40199999999999997\n",
      "completed DecisionTreeClassifier 0.6880000000000001\n",
      "completed GaussianNB 0.721\n",
      "completed RandomForestClassifier 0.769\n",
      "completed KNeighborsClassifier 0.6719999999999999\n",
      "completed IsolationForest 0.0\n",
      "completed GradientBoostingClassifier 0.7710000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed AdaBoostClassifier 0.6910000000000001\n",
      "completed GaussianProcessClassifier 0.666\n",
      "completed MLPClassifier 0.6\n",
      "completed BaggingClassifier 0.736\n",
      "completed RidgeClassifierCV 0.659\n",
      "completed ExtraTreesClassifier 0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed StackingClassifier 0.7769999999999999\n",
      "(0.7769999999999999, 'StackingClassifier')\n",
      "(0.7710000000000001, 'GradientBoostingClassifier')\n",
      "(0.769, 'RandomForestClassifier')\n",
      "(0.764, 'ExtraTreesClassifier')\n",
      "(0.736, 'BaggingClassifier')\n",
      "(0.721, 'GaussianNB')\n",
      "(0.704, 'SVM line')\n",
      "(0.6910000000000001, 'AdaBoostClassifier')\n",
      "(0.6880000000000001, 'DecisionTreeClassifier')\n",
      "(0.6719999999999999, 'KNeighborsClassifier')\n",
      "(0.666, 'GaussianProcessClassifier')\n",
      "(0.659, 'RidgeClassifierCV')\n",
      "(0.6, 'MLPClassifier')\n",
      "(0.40199999999999997, 'SVM sig')\n",
      "(0.40199999999999997, 'SVM rbf')\n",
      "(0.40199999999999997, 'SVM poly')\n",
      "(0.0, 'IsolationForest')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate, LeaveOneOut, train_test_split, StratifiedKFold\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# this is the one that sklearn uses as random state. edit: does not seem to work every time\n",
    "np.random.seed(2421)\n",
    "\n",
    "models = {\n",
    "    \"SVM rbf\": SVC(random_state=2421),\n",
    "    \"SVM poly\": SVC(kernel=\"poly\", random_state=2421),\n",
    "    \"SVM line\": SVC(kernel=\"linear\", random_state=2421),\n",
    "    \"SVM sig\": SVC(kernel=\"sigmoid\", random_state=2421),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=2421),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=2421),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"IsolationForest\": IsolationForest(random_state=2421),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=2421),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=2421),\n",
    "    \"GaussianProcessClassifier\": GaussianProcessClassifier(random_state=2421),\n",
    "    \"MLPClassifier\": MLPClassifier(random_state=2421),\n",
    "    \"BaggingClassifier\": BaggingClassifier(random_state=2421),\n",
    "    \"RidgeClassifierCV\": RidgeClassifierCV(),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=2421),\n",
    "}\n",
    "\n",
    "\n",
    "# Define base estimators for StackingClassifier\n",
    "base_estimators = [\n",
    "    ('gbc', GradientBoostingClassifier(random_state=2421)),\n",
    "    ('svm', SVC(kernel='linear', random_state=2421)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=2421)),\n",
    "    ('bagging', BaggingClassifier(random_state=2421)),\n",
    "    ('ada', AdaBoostClassifier(random_state=2421)),\n",
    "    ('GaussianNB', GaussianNB()),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier(random_state=2421)),\n",
    "]\n",
    "\n",
    "# Create StackingClassifier model\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_estimators, final_estimator=RandomForestClassifier(random_state=2421), cv=5\n",
    ")\n",
    "models[\"StackingClassifier\"] = stacking_clf\n",
    "\n",
    "results = list()\n",
    "for name, model in models.items():\n",
    "    result = cross_validate(model, X, y, cv=StratifiedKFold(\n",
    "        n_splits=5, shuffle=True, random_state=2421), scoring='accuracy', verbose=1)\n",
    "    results.append((np.mean(result['test_score']), name))\n",
    "    print(\"completed\", name, np.mean(result['test_score']))\n",
    "\n",
    "\n",
    "results.sort(reverse=True)\n",
    "for i in results:\n",
    "    print(i)\n",
    "\n",
    "\n",
    "# TODO vi vill bara anvnda leaveOneOut p sista nr vi tweakar\n",
    "# cv_results = cross_validate(models[results[0][1]], X, y, cv=LeaveOneOut(), scoring='accuracy')\n",
    "# cv_results2 = cross_validate(models[results[1][1]], X, y, cv=LeaveOneOut(), scoring='accuracy')\n",
    "# print(np.mean(cv_results['test_score']))\n",
    "# print(np.mean(cv_results2['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we use PCA also on the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.39531575e+00 -2.14463925e+00  3.63546999e-01 ...  4.30479169e-05\n",
      "  -8.78470809e-08  3.20484759e-15]\n",
      " [-5.49875461e+00  3.75376195e+00 -2.01568727e+00 ... -6.83574245e-05\n",
      "   9.11278224e-07 -5.55894484e-17]\n",
      " [ 1.08976345e+00  3.19492671e+00  8.20527727e-01 ...  4.55946643e-04\n",
      "   2.07679361e-06 -4.17078481e-16]\n",
      " ...\n",
      " [ 3.13218302e+00  6.58249503e-01 -5.59082807e+00 ... -6.03579389e-04\n",
      "  -4.04572616e-06  2.06820487e-17]\n",
      " [-4.70287020e+00  6.28841849e+00 -3.66218187e-02 ...  4.42635605e-04\n",
      "  -8.36450319e-07 -3.79522604e-17]\n",
      " [ 3.37137501e+00  1.03602141e+00  1.91259138e+00 ... -3.43179268e-04\n",
      "  -4.36009057e-06 -1.95641709e-18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed SVM rbf 0.743\n",
      "completed SVM poly 0.666\n",
      "completed SVM line 0.702\n",
      "completed SVM sig 0.53\n",
      "completed DecisionTreeClassifier 0.7919999999999999\n",
      "completed GaussianNB 0.829\n",
      "completed RandomForestClassifier 0.8550000000000001\n",
      "completed KNeighborsClassifier 0.6719999999999999\n",
      "completed IsolationForest 0.0\n",
      "completed GradientBoostingClassifier 0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed AdaBoostClassifier 0.7569999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed AdaBoostClassifierGradient 0.868\n",
      "completed GaussianProcessClassifier 0.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed MLPClassifier 0.7569999999999999\n",
      "completed BaggingClassifier 0.8379999999999999\n",
      "completed BaggingClassifierGradient 0.8709999999999999\n",
      "completed RidgeClassifierCV 0.659\n",
      "completed ExtraTreesClassifier 0.859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed StackingClassifier 0.8640000000000001\n",
      "(0.873, 'GradientBoostingClassifier')\n",
      "(0.8709999999999999, 'BaggingClassifierGradient')\n",
      "(0.868, 'AdaBoostClassifierGradient')\n",
      "(0.8640000000000001, 'StackingClassifier')\n",
      "(0.859, 'ExtraTreesClassifier')\n",
      "(0.8550000000000001, 'RandomForestClassifier')\n",
      "(0.8379999999999999, 'BaggingClassifier')\n",
      "(0.829, 'GaussianNB')\n",
      "(0.7919999999999999, 'DecisionTreeClassifier')\n",
      "(0.7569999999999999, 'MLPClassifier')\n",
      "(0.7569999999999999, 'AdaBoostClassifier')\n",
      "(0.743, 'SVM rbf')\n",
      "(0.702, 'SVM line')\n",
      "(0.6719999999999999, 'KNeighborsClassifier')\n",
      "(0.666, 'SVM poly')\n",
      "(0.666, 'GaussianProcessClassifier')\n",
      "(0.659, 'RidgeClassifierCV')\n",
      "(0.53, 'SVM sig')\n",
      "(0.0, 'IsolationForest')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate, LeaveOneOut, train_test_split, StratifiedKFold\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# this is the one that sklearn uses as random state. edit: does not seem to work every time\n",
    "np.random.seed(2421)\n",
    "\n",
    "models = {\n",
    "    \"SVM rbf\": SVC(random_state=2421),\n",
    "    \"SVM poly\": SVC(kernel=\"poly\", random_state=2421),\n",
    "    \"SVM line\": SVC(kernel=\"linear\", random_state=2421),\n",
    "    \"SVM sig\": SVC(kernel=\"sigmoid\", random_state=2421),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=2421),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=2421),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"IsolationForest\": IsolationForest(random_state=2421),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=2421),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=2421),\n",
    "    \"AdaBoostClassifierGradient\": AdaBoostClassifier(estimator=GradientBoostingClassifier(random_state=2421), random_state=2421),\n",
    "    \"GaussianProcessClassifier\": GaussianProcessClassifier(random_state=2421),\n",
    "    \"MLPClassifier\": MLPClassifier(random_state=2421),\n",
    "    \"BaggingClassifier\": BaggingClassifier(random_state=2421),\n",
    "    \"BaggingClassifierGradient\": BaggingClassifier(estimator=GradientBoostingClassifier(random_state=2421), random_state=2421),\n",
    "    \"RidgeClassifierCV\": RidgeClassifierCV(),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=2421),\n",
    "}\n",
    "\n",
    "\n",
    "# Define base estimators for StackingClassifier\n",
    "base_estimators = [\n",
    "    ('gbc', GradientBoostingClassifier(random_state=2421)),\n",
    "    ('svm', SVC(kernel='linear', random_state=2421)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=2421)),\n",
    "    ('bagging', BaggingClassifier(random_state=2421)),\n",
    "    ('ada', AdaBoostClassifier(random_state=2421)),\n",
    "    ('GaussianNB', GaussianNB()),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier(random_state=2421)),\n",
    "]\n",
    "\n",
    "# Create StackingClassifier model\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_estimators, final_estimator=RandomForestClassifier(random_state=2421), cv=5\n",
    ")\n",
    "models[\"StackingClassifier\"] = stacking_clf\n",
    "\n",
    "results = list()\n",
    "for name, model in models.items():\n",
    "    result = cross_validate(model, X, y, cv=StratifiedKFold(\n",
    "        n_splits=5, shuffle=True, random_state=2421), scoring='accuracy', verbose=1)\n",
    "    results.append((np.mean(result['test_score']), name))\n",
    "    print(\"completed\", name, np.mean(result['test_score']))\n",
    "\n",
    "\n",
    "results.sort(reverse=True)\n",
    "for i in results:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOW! We can test different paramaters for BaggingClassifierGradient to try to get even better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  10 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-2)]: Done  33 out of  40 | elapsed:   37.5s remaining:    7.9s\n",
      "[Parallel(n_jobs=-2)]: Done  40 out of  40 | elapsed:   47.3s finished\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed BaggingClassifierGradient10 0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done  10 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-2)]: Done  33 out of  40 | elapsed:  1.1min remaining:   14.4s\n",
      "[Parallel(n_jobs=-2)]: Done  40 out of  40 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed BaggingClassifierGradient20 0.8780000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done  10 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-2)]: Done  33 out of  40 | elapsed:  2.3min remaining:   29.0s\n",
      "[Parallel(n_jobs=-2)]: Done  40 out of  40 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed BaggingClassifierGradient40 0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done  10 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-2)]: Done  33 out of  40 | elapsed:  3.5min remaining:   44.6s\n",
      "[Parallel(n_jobs=-2)]: Done  40 out of  40 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed BaggingClassifierGradient60 0.8789999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done  10 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-2)]: Done  33 out of  40 | elapsed:  4.6min remaining:   58.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed BaggingClassifierGradient80 0.881\n",
      "(0.881, 'BaggingClassifierGradient80')\n",
      "(0.881, 'BaggingClassifierGradient40')\n",
      "(0.8789999999999999, 'BaggingClassifierGradient60')\n",
      "(0.8780000000000001, 'BaggingClassifierGradient20')\n",
      "(0.873, 'BaggingClassifierGradient10')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done  40 out of  40 | elapsed:  5.9min finished\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"BaggingClassifierGradient10\": BaggingClassifier(estimator=GradientBoostingClassifier(random_state=2421), random_state=2421, n_estimators=10),\n",
    "    \"BaggingClassifierGradient20\": BaggingClassifier(estimator=GradientBoostingClassifier(random_state=2421), random_state=2421, n_estimators=20),\n",
    "    \"BaggingClassifierGradient40\": BaggingClassifier(estimator=GradientBoostingClassifier(random_state=2421), random_state=2421, n_estimators=40),\n",
    "    \"BaggingClassifierGradient60\": BaggingClassifier(estimator=GradientBoostingClassifier(random_state=2421), random_state=2421, n_estimators=60),\n",
    "    \"BaggingClassifierGradient80\": BaggingClassifier(estimator=GradientBoostingClassifier(random_state=2421), random_state=2421, n_estimators=80),\n",
    "}\n",
    "\n",
    "\n",
    "results = list()\n",
    "for name, model in models.items():\n",
    "    result = cross_validate(model, X, y, cv=StratifiedKFold(\n",
    "        n_splits=40, shuffle=True, random_state=2421), scoring='accuracy', verbose=3, n_jobs=-2)\n",
    "\n",
    "    results.append((np.mean(result['test_score']), name))\n",
    "    print(\"completed\", name, np.mean(result['test_score']))\n",
    "\n",
    "\n",
    "results.sort(reverse=True)\n",
    "for i in results:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  10 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-2)]: Done 106 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-2)]: Done 266 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-2)]: Done 490 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-2)]: Done 778 tasks      | elapsed: 15.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed BaggingClassifierGradient80 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed: 19.4min finished\n"
     ]
    }
   ],
   "source": [
    "model = BaggingClassifier(estimator=GradientBoostingClassifier(\n",
    "    random_state=2421), random_state=2421, n_estimators=10)\n",
    "result = cross_validate(model, X, y, cv=LeaveOneOut(),\n",
    "                        scoring='accuracy', verbose=3, n_jobs=-2)\n",
    "print(\"completed\", name, np.mean(result['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  10 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=-2)]: Done 106 tasks      | elapsed:  7.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed BaggingClassifierGradient80 0.8760000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed: 14.6min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "\n",
    "\n",
    "model = BaggingClassifier(estimator=GradientBoostingClassifier(\n",
    "    random_state=2421), random_state=2421, n_estimators=40)\n",
    "result = cross_validate(model, X, y, cv=StratifiedKFold(\n",
    "    n_splits=200, shuffle=True, random_state=2421),\n",
    "    scoring='accuracy', verbose=3, n_jobs=-2)\n",
    "print(\"completed\", name, np.mean(result['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "evaluation_data = pca.fit_transform(evaluation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ken' 'Barbie' 'Barbie' ... 'Allan' 'Allan' 'Barbie']\n",
      "['Ken' 'Barbie' 'Barbie' ... 'Allan' 'Allan' 'Barbie']\n",
      "['Ken' 'Barbie' 'Barbie' ... 'Allan' 'Allan' 'Barbie']\n"
     ]
    }
   ],
   "source": [
    "prediction = BaggingClassifier(estimator=GradientBoostingClassifier(\n",
    "    random_state=2421), random_state=2421, n_estimators=10).fit(X, y).predict(evaluation_data)\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "f = open(\"predictions10.txt\", 'w')\n",
    "\n",
    "\n",
    "for word in prediction:\n",
    "\n",
    "    f.write(word + \"\\n\")\n",
    "\n",
    "\n",
    "f.close()\n",
    "\n",
    "prediction2 = BaggingClassifier(estimator=GradientBoostingClassifier(\n",
    "    random_state=2421), random_state=2421, n_estimators=40).fit(X, y).predict(evaluation_data)\n",
    "\n",
    "print(prediction2)\n",
    "\n",
    "f = open(\"predictions40.txt\", 'w')\n",
    "for word in prediction2:\n",
    "    f.write(word + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "prediction3 = BaggingClassifier(estimator=GradientBoostingClassifier(\n",
    "    random_state=2421), random_state=2421, n_estimators=60).fit(X, y).predict(evaluation_data)\n",
    "\n",
    "print(prediction3)\n",
    "\n",
    "f = open(\"predictions60.txt\", 'w')\n",
    "for word in prediction3:\n",
    "    f.write(word + \"\\n\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
